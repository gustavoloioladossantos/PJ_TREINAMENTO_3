{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar coluna de store segment em 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from math import ceil  # Importar a função ceil\n",
    "\n",
    "pd.options.display.max_columns=70 \n",
    "pd.options.display.max_rows=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_percent(data):\n",
    "    \"\"\"\n",
    "    Retorna dataframe contendo o total de valores faltantes e porcentagem do total\n",
    "    de valores faltantes da coluna.\n",
    "    \"\"\"\n",
    "    miss_df = pd.DataFrame({'ColumnName':[],'TotalMissingVals':[],'PercentMissing':[]})\n",
    "    for col in data.columns:\n",
    "        sum_miss_val = data[col].isnull().sum()\n",
    "        percent_miss_val = round((sum_miss_val/data.shape[0])*100,2)\n",
    "        miss_df.loc[len(miss_df)] = dict(zip(miss_df.columns,[col,sum_miss_val,percent_miss_val]))\n",
    "    return miss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlated_columns(df, interval):\n",
    "    \"\"\"\n",
    "    Encontra e exibe as correlações entre colunas de um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df: DataFrame pandas\n",
    "    - intervalo de correlação desejado (uma tupla de dois valores)\n",
    "\n",
    "    Retorna:\n",
    "    - Lista de tuplas representando pares de colunas correlacionadas.\n",
    "    \"\"\"\n",
    "    correlation_matrix = df.corr(numeric_only=True)\n",
    "    correlated_columns = []\n",
    "\n",
    "    # Iterar sobre as combinações de colunas para encontrar correlações\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            corr = correlation_matrix.iloc[i, j]\n",
    "            if interval[0] <= abs(corr) <= interval[1]:\n",
    "                col1 = correlation_matrix.columns[i]\n",
    "                col2 = correlation_matrix.columns[j]\n",
    "                correlated_columns.append((col1, col2))\n",
    "                print(f\"Correlação entre {col1} e {col2}: {corr}\")\n",
    "\n",
    "    # Plotar um mapa de calor da matriz de correlação\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='cubehelix_r')\n",
    "    plt.title('Matriz de Correlação')\n",
    "    plt.xlabel('Variáveis')\n",
    "    plt.ylabel('Variáveis')\n",
    "    plt.show()\n",
    "\n",
    "    return correlated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlacao_com_variavel_alvo(df, target_variable, nivel=\"forte\", top_n=5):\n",
    "    \"\"\"\n",
    "    Imprime as n features com as maiores correlações com uma variável alvo, com base no nível escolhido.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df: DataFrame pandas.\n",
    "    - target_variable: String, nome da variável alvo.\n",
    "    - nivel: String que define o critério de correlação (\"forte\", \"fraca\", etc.).\n",
    "    - top_n: Número inteiro, quantidade de features a serem impressas.\n",
    "\n",
    "    Retorna:\n",
    "    - Nenhum (imprime as correlações).\n",
    "    \"\"\"\n",
    "    correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "    # Filtra as correlações com base no nível escolhido\n",
    "    if nivel.lower() == \"forte\":\n",
    "        filtered_correlations = correlation_matrix[((correlation_matrix >= 0.7) & (correlation_matrix < 1.0)) | ((correlation_matrix <= -0.7) & (correlation_matrix > -1.0))]\n",
    "    else:\n",
    "        raise ValueError(\"Nível não suportado. Atualmente, apenas 'forte' é suportado.\")\n",
    "\n",
    "    # Filtra as correlações com a variável alvo\n",
    "    correlations_with_target = filtered_correlations[target_variable].sort_values(ascending=False)\n",
    "\n",
    "    # Pegar as n maiores correlações\n",
    "    top_n_correlations = correlations_with_target.head(top_n)\n",
    "\n",
    "    # Imprimir as n maiores correlações com a variável alvo\n",
    "    print(f\"As {top_n} maiores correlações com '{target_variable}' ({nivel}):\")\n",
    "    for feature, correlation in top_n_correlations.items():\n",
    "        print(f\"{feature}: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_limpa.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preenchendo valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores outliers já foram tratados na etapa de limpeza dos dados, agora cabe lidar com os valores nulos para viabilizar a utilização dos modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_limpa.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantendo somente os pedidos que não foram cancelados para que possamos analisar os tempos de entrega\n",
    "df = df[~df['order_status'].eq('CANCELED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_percent(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo pedidos sem o tempo de entrega 'order_metric_cycle_time'\n",
    "df = df[~df['order_metric_cycle_time'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['store_plan_price'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment_status'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['driver_modal', 'driver_type', 'payment_method', 'payment_status']:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "for column in ['delivery_distance_meters',  'payment_amount', 'payment_fee', \n",
    "                'order_delivery_cost']:\n",
    "    df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Preencher NaN em 'delivery_status' com 'DELIVERED' onde 'order_metric_cycle_time' não é NaN\n",
    "df.loc[df['order_metric_cycle_time'].notnull() & df['delivery_status'].isnull(), 'delivery_status'] = 'DELIVERED'\n",
    "\n",
    "# Calcular o segundo valor mais frequente em 'delivery_status'\n",
    "second_most_frequent_value = df['delivery_status'].value_counts().index[1]\n",
    "\n",
    "# Preencher NaN em 'delivery_status' com o segundo valor mais frequente\n",
    "df['delivery_status'].fillna(second_most_frequent_value, inplace=True)\n",
    "\n",
    "\n",
    "# Condição para preencher apenas quando delivery_status for 'DELIVERED'\n",
    "condition = df['delivery_status'] == 'DELIVERED'\n",
    "\n",
    "# Lista das colunas a serem preenchidas com a mediana\n",
    "columns_to_fill = [\n",
    "    'order_metric_production_time', \n",
    "    'order_metric_expediton_speed_time', \n",
    "    'order_metric_transit_time', \n",
    "    'order_metric_collected_time', \n",
    "    'order_metric_paused_time', \n",
    "    'order_metric_walking_time',\n",
    "    'order_metric_cycle_time'  # Adicionando 'order_metric_cycle_time' à lista\n",
    "]\n",
    "\n",
    "# Preencher os valores faltantes com a mediana nas colunas específicas quando delivery_status for 'DELIVERED'\n",
    "for column in columns_to_fill:\n",
    "    median_value = df.loc[condition, column].median()\n",
    "    df.loc[condition & df[column].isnull(), column] = median_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['hub_name', 'hub_city', 'hub_state', 'store_name', 'store_segment',\n",
    "       'store_plan_price', 'driver_modal', 'driver_type',\n",
    "       'delivery_distance_meters', 'delivery_status', 'payment_amount',\n",
    "       'payment_fee', 'payment_method', 'payment_status', 'channel_name',\n",
    "       'channel_type', 'order_status', 'order_amount', 'order_delivery_fee',\n",
    "       'order_delivery_cost', 'order_moment_created', 'order_moment_accepted',\n",
    "       'order_moment_ready', 'order_moment_collected',\n",
    "       'order_moment_in_expedition', 'order_moment_delivering',\n",
    "       'order_moment_finished', 'order_metric_collected_time',\n",
    "       'order_metric_paused_time', 'order_metric_production_time',\n",
    "       'order_metric_walking_time', 'order_metric_expediton_speed_time',\n",
    "       'order_metric_transit_time', 'order_metric_cycle_time', 'tempo_entrega',\n",
    "       'order_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols_categoric = ['hub_state', 'store_segment', 'driver_modal', 'channel_type']\n",
    "input_cols_numeric = ['delivery_distance_meters', 'payment_amount', 'order_amount', 'order_moment_accepted', 'weekday']\n",
    "input_cols = input_cols_categoric + input_cols_categoric\n",
    "\n",
    "target_col = ['order_metric_cycle_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
